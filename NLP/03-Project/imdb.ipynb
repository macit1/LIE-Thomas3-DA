{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment     label\n",
      "0  Ok, first the good: Cher's performance and the...  negative\n",
      "1  This movie has Wild Bill Hickok, Calamity Jane...  positive\n",
      "2  An actress making a movie in Africa is kidnapp...  negative\n",
      "3  All the talent Mr. Sooraj Barjatya showed in h...  positive\n",
      "4  Sexo Cannibal, or Devil Hunter as it's more co...  negative\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory paths for positive and negative comments\n",
    "positive_dir = r'C:\\Users\\macit\\Documents\\Visual_Studio_Projects\\LIE-Thomas3-DA\\NLP\\03-Project\\aclImdb\\train_created\\pos'\n",
    "negative_dir = r'C:\\Users\\macit\\Documents\\Visual_Studio_Projects\\LIE-Thomas3-DA\\NLP\\03-Project\\aclImdb\\train_created\\neg'\n",
    "\n",
    "# Function to read comments from a directory\n",
    "def read_comments_from_directory(directory, label):\n",
    "    comments = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                comment = file.read()\n",
    "                comments.append({'comment': comment, 'label': label})\n",
    "    return comments\n",
    "\n",
    "# Read positive and negative comments\n",
    "positive_comments = read_comments_from_directory(positive_dir, label='positive')\n",
    "negative_comments = read_comments_from_directory(negative_dir, label='negative')\n",
    "\n",
    "# Combine positive and negative comments into a single DataFrame\n",
    "comments_df = pd.DataFrame(positive_comments + negative_comments)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "comments_df = comments_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the combined dataset\n",
    "print(comments_df.head())\n",
    "\n",
    "# Optionally, save the combined dataset to a CSV file\n",
    "comments_df.to_csv('combined_comments.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ok, first the good: Cher's performance and the...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie has Wild Bill Hickok, Calamity Jane...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An actress making a movie in Africa is kidnapp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All the talent Mr. Sooraj Barjatya showed in h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sexo Cannibal, or Devil Hunter as it's more co...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>I am not so much like Love Sick as I image. Fi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>what ends up killing this movie is its self-co...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>This movie just pulls you so deeply into the t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>I was one of quite a few extras in this big bo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Hilariously obvious \"drama\" about a bunch of h...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment     label\n",
       "0     Ok, first the good: Cher's performance and the...  negative\n",
       "1     This movie has Wild Bill Hickok, Calamity Jane...  positive\n",
       "2     An actress making a movie in Africa is kidnapp...  negative\n",
       "3     All the talent Mr. Sooraj Barjatya showed in h...  positive\n",
       "4     Sexo Cannibal, or Devil Hunter as it's more co...  negative\n",
       "...                                                 ...       ...\n",
       "1997  I am not so much like Love Sick as I image. Fi...  negative\n",
       "1998  what ends up killing this movie is its self-co...  negative\n",
       "1999  This movie just pulls you so deeply into the t...  positive\n",
       "2000  I was one of quite a few extras in this big bo...  negative\n",
       "2001  Hilariously obvious \"drama\" about a bunch of h...  negative\n",
       "\n",
       "[2002 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\macit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\macit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  \\\n",
      "0  Ok, first the good: Cher's performance and the...   \n",
      "1  This movie has Wild Bill Hickok, Calamity Jane...   \n",
      "2  An actress making a movie in Africa is kidnapp...   \n",
      "3  All the talent Mr. Sooraj Barjatya showed in h...   \n",
      "4  Sexo Cannibal, or Devil Hunter as it's more co...   \n",
      "\n",
      "                                preprocessed_comment     label  \n",
      "0  Ok first good Chers performance cinematography...  negative  \n",
      "1  This movie Wild Bill Hickok Calamity Jane Buff...  positive  \n",
      "2  An actress making movie Africa kidnapped taken...  negative  \n",
      "3  All talent Mr Sooraj Barjatya showed first mov...  positive  \n",
      "4  Sexo Cannibal Devil Hunter commonly known amon...  negative  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove '<br /><br />' pattern\n",
    "    text = re.sub(r'<br\\s?/>', ' ', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply preprocessing to the 'comment' column\n",
    "comments_df['preprocessed_comment'] = comments_df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the updated preprocessed dataset\n",
    "print(comments_df[['comment', 'preprocessed_comment', 'label']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ok first good Chers performance cinematography...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie Wild Bill Hickok Calamity Jane Buff...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An actress making movie Africa kidnapped taken...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All talent Mr Sooraj Barjatya showed first mov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sexo Cannibal Devil Hunter commonly known amon...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>I much like Love Sick I image Finally film exp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>end killing movie selfconsciousness among thin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>This movie pull deeply two main character I po...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>I one quite extra big bomb I happened right pl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Hilariously obvious drama bunch high school I ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   preprocessed_comment     label\n",
       "0     Ok first good Chers performance cinematography...  negative\n",
       "1     This movie Wild Bill Hickok Calamity Jane Buff...  positive\n",
       "2     An actress making movie Africa kidnapped taken...  negative\n",
       "3     All talent Mr Sooraj Barjatya showed first mov...  positive\n",
       "4     Sexo Cannibal Devil Hunter commonly known amon...  negative\n",
       "...                                                 ...       ...\n",
       "1997  I much like Love Sick I image Finally film exp...  negative\n",
       "1998  end killing movie selfconsciousness among thin...  negative\n",
       "1999  This movie pull deeply two main character I po...  positive\n",
       "2000  I one quite extra big bomb I happened right pl...  negative\n",
       "2001  Hilariously obvious drama bunch high school I ...  negative\n",
       "\n",
       "[2002 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = comments_df[['preprocessed_comment', 'label']].copy()\n",
    "\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\macit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\macit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\macit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 32)           717760    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               800250    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1518261 (5.79 MB)\n",
      "Trainable params: 1518261 (5.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\Users\\macit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\macit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "13/13 - 3s - loss: 0.6936 - accuracy: 0.5041 - val_loss: 0.6886 - val_accuracy: 0.5362 - 3s/epoch - 258ms/step\n",
      "Epoch 2/2\n",
      "13/13 - 1s - loss: 0.6474 - accuracy: 0.7283 - val_loss: 0.6894 - val_accuracy: 0.5436 - 606ms/epoch - 47ms/step\n",
      "Accuracy: 54.36%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "# Assuming 'comments_df' has 'comment' and 'label' columns\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(comments_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Your preprocessing steps here (e.g., HTML tag removal, special character removal, tokenization, etc.)\n",
    "    return text\n",
    "\n",
    "train_df['preprocessed_comment'] = train_df['comment'].apply(preprocess_text)\n",
    "test_df['preprocessed_comment'] = test_df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Step 3: Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df['label'])\n",
    "test_labels_encoded = label_encoder.transform(test_df['label'])\n",
    "\n",
    "# Step 4: Tokenize and pad sequences\n",
    "max_words = 100  # Choose an appropriate value\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_df['preprocessed_comment'])\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_df['preprocessed_comment'])\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_df['preprocessed_comment'])\n",
    "\n",
    "max_length = 100  # Choose an appropriate value\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Step 5: Build the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Step 6: Fit the model\n",
    "model.fit(X_train_padded, train_labels_encoded, validation_data=(X_test_padded, test_labels_encoded), epochs=2, batch_size=128, verbose=2)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "scores = model.evaluate(X_test_padded, test_labels_encoded, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_encoded\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
